{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA e Classifica√ß√£o com √Årvore de Decis√£o: Otimiza√ß√£o da Dimensionalidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdu√ß√£o\n",
    "Nesta an√°lise, exploramos a aplica√ß√£o da An√°lise de Componentes Principais (PCA) para reduzir a dimensionalidade do conjunto de dados HAR (Human Activity Recognition) e avaliamos seu impacto no desempenho de um classificador baseado em √°rvore de decis√£o.\n",
    "\n",
    "Os principais objetivos s√£o:\n",
    "- Avaliar a acur√°cia do modelo sem redu√ß√£o de dimensionalidade.\n",
    "- Aplicar o PCA e testar a influ√™ncia da varia√ß√£o no n√∫mero de componentes principais.\n",
    "- Comparar o desempenho computacional e a acur√°cia nas bases de treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanks\\AppData\\Local\\Temp\\ipykernel_29020\\2403609656.py:12: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  features = pd.read_csv(filename_features, header=None, names=['nome_var'], squeeze=True, sep=\"#\")\n",
      "C:\\Users\\yanks\\AppData\\Local\\Temp\\ipykernel_29020\\2403609656.py:15: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  subject_train = pd.read_csv(filename_subtrain, header=None, names=['subject_id'], squeeze=True)\n",
      "C:\\Users\\yanks\\AppData\\Local\\Temp\\ipykernel_29020\\2403609656.py:19: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  subject_test = pd.read_csv(filename_subtest, header=None, names=['subject_id'], squeeze=True)\n"
     ]
    }
   ],
   "source": [
    "filename_features = \"features.txt\"\n",
    "filename_labels = \"activity_labels.txt\"\n",
    "\n",
    "filename_subtrain = \"subject_train.txt\"\n",
    "filename_xtrain = \"X_train.txt\"\n",
    "filename_ytrain = \"y_train.txt\"\n",
    "\n",
    "filename_subtest = \"subject_test.txt\"\n",
    "ffilename_xtest = \"X_test.txt\"\n",
    "filename_ytest = \"y_test.txt\"\n",
    "\n",
    "features = pd.read_csv(filename_features, header=None, names=['nome_var'], squeeze=True, sep=\"#\")\n",
    "labels = pd.read_csv(filename_labels, delim_whitespace=True, header=None, names=['cod_label', 'label'])\n",
    "\n",
    "subject_train = pd.read_csv(filename_subtrain, header=None, names=['subject_id'], squeeze=True)\n",
    "X_train = pd.read_csv(filename_xtrain, delim_whitespace=True, header=None, names=features.tolist())\n",
    "y_train = pd.read_csv(filename_ytrain, header=None, names=['cod_label'])\n",
    "\n",
    "subject_test = pd.read_csv(filename_subtest, header=None, names=['subject_id'], squeeze=True)\n",
    "X_test = pd.read_csv(ffilename_xtest, delim_whitespace=True, header=None, names=features.tolist())\n",
    "y_test = pd.read_csv(filename_ytest, header=None, names=['cod_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constru√ß√£o da √Årvore de Decis√£o sem Redu√ß√£o de Dimensionalidade\n",
    "Inicialmente, treinamos uma √°rvore de decis√£o utilizando todas as 561 vari√°veis dispon√≠veis no dataset, sem nenhuma t√©cnica de redu√ß√£o de dimensionalidade.\n",
    "\n",
    "üîπ **Hiperpar√¢metro utilizado:**\n",
    "\n",
    "`ccp_alpha = 0.001`: Aplica√ß√£o de poda para evitar overfitting.\n",
    "\n",
    "**Resultados Obtidos:**\n",
    "\n",
    "- Acur√°cia na base de treino: $88%$\n",
    "- Acur√°cia na base de teste: $87%$\n",
    "- Tempo de processamento: $\\sim3.19$ segundos\n",
    "\n",
    "Esse desempenho reflete a capacidade do modelo de aprender padr√µes complexos nos dados, mas tamb√©m sugere que a alta dimensionalidade pode estar influenciando a generaliza√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia na base de treinamento: 0.9757889009793254\n",
      "Acur√°cia na base de teste: 0.8812351543942993\n",
      "\n",
      "CPU times: total: 2.55 s\n",
      "Wall time: 3.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Medindo o tempo de processamento\n",
    "# A partir deste ponto, ser√° cronometrado o tempo necess√°rio para executar o c√≥digo abaixo.\n",
    "\n",
    "# Cria√ß√£o do classificador de √°rvore de decis√£o com ccp_alpha=0.001\n",
    "clf = DecisionTreeClassifier(ccp_alpha=0.001)\n",
    "\n",
    "# Treinamento do classificador utilizando os dados de treinamento\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Avalia√ß√£o da acur√°cia do classificador nos dados de treinamento\n",
    "print(f'Acur√°cia na base de treinamento: {clf.score(X_train, y_train)}')\n",
    "# Avalia√ß√£o da acur√°cia do classificador nos dados de teste\n",
    "print(f'Acur√°cia na base de teste: {clf.score(X_test, y_test)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplica√ß√£o do PCA e Avalia√ß√£o da √Årvore de Decis√£o\n",
    "O PCA foi aplicado ao conjunto de dados para reduzir a dimensionalidade, transformando as vari√°veis originais em componentes principais ortogonais. Para essa an√°lise inicial, utilizamos apenas uma componente principal, avaliando sua influ√™ncia na classifica√ß√£o.\n",
    "\n",
    "#### Resultados com PCA ($k=1$ componente):\n",
    "\n",
    "- Acur√°cia na base de treino: $49.97%$\n",
    "- Acur√°cia na base de teste: $45.70%$\n",
    "- Tempo de processamento: $\\sim955$ ms\n",
    "\n",
    "Observa√ß√£o: Com apenas uma componente principal, houve uma redu√ß√£o dr√°stica no tempo de processamento, mas a acur√°cia caiu significativamente. Isso sugere que uma √∫nica componente n√£o captura informa√ß√µes suficientes para a correta diferencia√ß√£o das atividades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimens√µes da base de treinamento: (7352, 1)\n",
      "Dimens√µes da base de teste: (2947, 1)\n",
      "Acur√°cia na base de treinamento: 0.499727965179543\n",
      "Acur√°cia na base de teste: 0.45707499151679676\n",
      "\n",
      "CPU times: total: 312 ms\n",
      "Wall time: 955 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Aplica o PCA com 1 componente aos dados de treinamento\n",
    "prcomp = PCA(n_components=1).fit(X_train)\n",
    "\n",
    "# Transforma os dados de treinamento e teste utilizando as componentes principais encontradas pelo PCA\n",
    "pc_treino = prcomp.transform(X_train)\n",
    "pc_teste  = prcomp.transform(X_test)\n",
    "\n",
    "# Imprime a forma dos dados de treinamento e teste ap√≥s a transforma√ß√£o\n",
    "print(f'Dimens√µes da base de treinamento: {pc_treino.shape}')\n",
    "print(f'Dimens√µes da base de teste: {pc_teste.shape}')\n",
    "\n",
    "# Inicializa um classificador de √°rvore de decis√£o com ccp_alpha=0.001 e treina-o com os dados de treinamento transformados\n",
    "clf = DecisionTreeClassifier(ccp_alpha=0.001)\n",
    "clf.fit(pc_treino, y_train)\n",
    "\n",
    "# Calcula e imprime a acur√°cia do classificador nos dados de treinamento e teste\n",
    "print(f'Acur√°cia na base de treinamento: {clf.score(pc_treino, y_train)}')\n",
    "print(f'Acur√°cia na base de teste: {clf.score(pc_teste, y_test)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste com Diferentes N√∫meros de Componentes\n",
    "Para entender o impacto do n√∫mero de componentes principais ($k$), testamos os seguintes valores:\n",
    "\n",
    "$$ k \\in {1, 2, 5, 10, 50} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimens√µes da base de treinamento: (7352, 1)\n",
      "Dimens√µes da base de teste: (2947, 1)\n",
      "Acur√°cia na base de treinamento: 0.499727965179543\n",
      "Acur√°cia na base de teste: 0.45707499151679676\n",
      "\n",
      "Dimens√µes da base de treinamento: (7352, 2)\n",
      "Dimens√µes da base de teste: (2947, 2)\n",
      "Acur√°cia na base de treinamento: 0.6127584330794341\n",
      "Acur√°cia na base de teste: 0.5846623685103495\n",
      "\n",
      "Dimens√µes da base de treinamento: (7352, 5)\n",
      "Dimens√µes da base de teste: (2947, 5)\n",
      "Acur√°cia na base de treinamento: 0.8460282916213275\n",
      "Acur√°cia na base de teste: 0.7885985748218527\n",
      "\n",
      "Dimens√µes da base de treinamento: (7352, 10)\n",
      "Dimens√µes da base de teste: (2947, 10)\n",
      "Acur√°cia na base de treinamento: 0.8926822633297062\n",
      "Acur√°cia na base de teste: 0.8238887003732609\n",
      "\n",
      "Dimens√µes da base de treinamento: (7352, 50)\n",
      "Dimens√µes da base de teste: (2947, 50)\n",
      "Acur√°cia na base de treinamento: 0.9171653971708379\n",
      "Acur√°cia na base de teste: 0.823549372242959\n",
      "\n",
      "CPU times: total: 3.98 s\n",
      "Wall time: 1.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "componentes = [1, 2, 5, 10, 50]\n",
    "\n",
    "# Loop sobre os diferentes n√∫meros de componentes\n",
    "for n in componentes:\n",
    "    # Executa o PCA com o n√∫mero de componentes atual\n",
    "    prcomp = PCA(n_components=n).fit(X_train)\n",
    "\n",
    "    # Transforma os dados de treinamento e teste nos componentes principais\n",
    "    pc_treino = prcomp.transform(X_train)\n",
    "    pc_teste  = prcomp.transform(X_test)\n",
    "\n",
    "    # Imprime as dimens√µes dos dados transformados\n",
    "    print(f'Dimens√µes da base de treinamento: {pc_treino.shape}')\n",
    "    print(f'Dimens√µes da base de teste: {pc_teste.shape}')\n",
    "\n",
    "    # Cria e treina um classificador de √°rvore de decis√£o\n",
    "    clf = DecisionTreeClassifier(ccp_alpha=0.001)\n",
    "    clf.fit(pc_treino, y_train)\n",
    "\n",
    "    # Avalia a acur√°cia na base de treinamento e teste\n",
    "    print(f'Acur√°cia na base de treinamento: {clf.score(pc_treino, y_train)}')\n",
    "    print(f'Acur√°cia na base de teste: {clf.score(pc_teste, y_test)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa√ß√µes:\n",
    "- O aumento do n√∫mero de componentes melhora progressivamente a acur√°cia, demonstrando que informa√ß√µes importantes estavam distribu√≠das entre m√∫ltiplas dimens√µes.\n",
    "- Com 50 componentes principais, atingimos 82% de acur√°cia na base de teste, um desempenho pr√≥ximo ao modelo original, por√©m com redu√ß√£o do tempo de processamento pela metade.\n",
    "- A curva de aprendizado do modelo sugere que o uso de um n√∫mero intermedi√°rio de componentes pode equilibrar efici√™ncia computacional e performance preditiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Conclus√£o\n",
    "Principais aprendizados deste estudo:\n",
    "- Redu√ß√£o de Dimensionalidade: O PCA permitiu reduzir drasticamente o tempo de processamento, tornando o modelo mais eficiente.\n",
    "- Impacto na Acur√°cia: Com poucas componentes, houve grande perda de performance. No entanto, com 50 componentes, o modelo se aproximou do desempenho original.\n",
    "- Equil√≠brio Ideal: Utilizar um n√∫mero adequado de componentes pode preservar a maior parte da informa√ß√£o relevante, reduzindo a complexidade sem perda excessiva de precis√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "√çndice",
   "title_sidebar": "Conte√∫do",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
