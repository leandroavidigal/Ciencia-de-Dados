# Boosting & Bagging - T√©cnicas de Ensemble Learning Aplicadas

Este reposit√≥rio re√∫ne estudos detalhados e implementa√ß√µes pr√°ticas das principais t√©cnicas de **Ensemble Learning**, incluindo **Bagging, Random Forest, AdaBoost e Gradient Boosting Machine (GBM)**. Cada projeto explora desde os fundamentos te√≥ricos at√© a aplica√ß√£o pr√°tica, otimiza√ß√£o de hiperpar√¢metros e compara√ß√µes entre os m√©todos.

---

## üìå Projetos

### **1Ô∏è‚É£ Bagging - Estrat√©gia de Ensemble Learning para Modelos Preditivos**
**Objetivo:**  
Explorar o **Bagging (Bootstrap Aggregating)**, uma t√©cnica de aprendizado de m√°quina que reduz a vari√¢ncia dos modelos combinando previs√µes de m√∫ltiplos aprendizes treinados em subconjuntos de dados gerados por amostragem com reposi√ß√£o.

**Principais t√≥picos abordados:**
‚úîÔ∏è Conceito de **Bagging** e como ele melhora a estabilidade dos modelos.  
‚úîÔ∏è Implementa√ß√£o de **Bagging** para **classifica√ß√£o e regress√£o** utilizando **√°rvores de decis√£o**.  
‚úîÔ∏è Compara√ß√£o de desempenho com **modelos individuais**.  

---

### **2Ô∏è‚É£ Implementa√ß√£o do Algoritmo Random Forest**
**Objetivo:**  
Desenvolver o algoritmo **Random Forest** do zero, aplicando seus princ√≠pios fundamentais de **Bagging + Sele√ß√£o Aleat√≥ria de Recursos**.

**Principais t√≥picos abordados:**
‚úîÔ∏è Conceito de **Random Forest** e sua rela√ß√£o com o Bagging.  
‚úîÔ∏è Constru√ß√£o de um modelo **Random Forest para classifica√ß√£o e regress√£o**.  
‚úîÔ∏è Compara√ß√£o entre **Random Forest e modelos individuais** para avaliar ganhos em generaliza√ß√£o.  

---

### **3Ô∏è‚É£ Hiperpar√¢metros do Random Forest (RF) e Seus Prop√≥sitos**
**Objetivo:**  
Analisar os principais **hiperpar√¢metros do Random Forest**, explicando seus impactos e como otimiz√°-los para maximizar a performance do modelo.

**Principais t√≥picos abordados:**
‚úîÔ∏è **Explica√ß√£o matem√°tica e intuitiva** dos hiperpar√¢metros do Random Forest.  

---

### **4Ô∏è‚É£ Random Forest vs AdaBoost - Compara√ß√£o e Otimiza√ß√£o**
**Objetivo:**  
Comparar os algoritmos **Random Forest** e **AdaBoost**, explorando suas diferen√ßas em **metodologia, ajuste de erro e robustez**.

**Principais t√≥picos abordados:**
‚úîÔ∏è Diferen√ßas entre **Bagging (Random Forest) e Boosting (AdaBoost)**.  
‚úîÔ∏è Implementa√ß√£o e avalia√ß√£o dos **dois modelos em classifica√ß√£o e regress√£o**.  
‚úîÔ∏è Compara√ß√£o de **acur√°cia, robustez a ru√≠do e tempo de treinamento**.  

---

### **5Ô∏è‚É£ AdaBoost vs Gradient Boosting Machine (GBM)**
**Objetivo:**  
Explorar as diferen√ßas entre **AdaBoost e GBM**, aprofundando os conceitos de **ajuste de erro sequencial e otimiza√ß√£o de gradiente**.

**Principais t√≥picos abordados:**
‚úîÔ∏è **Compara√ß√£o te√≥rica** entre AdaBoost e GBM.  
‚úîÔ∏è **Implementa√ß√£o e otimiza√ß√£o** de ambos os modelos para classifica√ß√£o e regress√£o.  
‚úîÔ∏è Uso de **GridSearch** para ajuste de hiperpar√¢metros do GBM.  

---

## **Tecnologias Utilizadas**
- **Python** 
- **Scikit-Learn** (modelagem estat√≠stica e machine learning)  
- **Pandas & NumPy** (manipula√ß√£o e an√°lise de dados)  
- **Matplotlib & Seaborn**  (visualiza√ß√£o de dados)  

---

## **Conclus√£o**
Este reposit√≥rio serve como um guia completo para quem deseja entender e aplicar **t√©cnicas de Ensemble Learning** no contexto de Machine Learning. Cada projeto apresenta os fundamentos te√≥ricos, implementa√ß√£o pr√°tica e otimiza√ß√£o dos modelos, proporcionando uma base s√≥lida para a constru√ß√£o de **modelos preditivos mais robustos e generaliz√°veis**. 
