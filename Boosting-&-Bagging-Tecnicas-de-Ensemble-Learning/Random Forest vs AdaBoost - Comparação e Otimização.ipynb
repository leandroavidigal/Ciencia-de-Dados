{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d9d7e5-dd35-4222-9f5b-2ad51ce3291f",
   "metadata": {},
   "source": [
    "# Random Forest vs AdaBoost: Comparação e Otimização\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db295d28-729f-4b9f-943b-bc31ccb47ce2",
   "metadata": {},
   "source": [
    "## **1. Diferenças Fundamentais entre Random Forest e AdaBoost**\n",
    "\n",
    "O **Random Forest** e o **AdaBoost** são dois algoritmos poderosos da família de **ensemble learning**, mas possuem diferenças fundamentais em sua concepção e funcionamento. A seguir, destacamos **cinco principais diferenças** entre esses dois métodos:\n",
    "\n",
    "### **Estratégia de Construção do Modelo**\n",
    "- **Random Forest (RF)**: Constrói **múltiplas árvores de decisão independentes** em paralelo, cada uma treinada em uma amostra bootstrap do conjunto de dados. A previsão final é obtida por **votação majoritária** (classificação) ou **média das previsões** (regressão).\n",
    "  \n",
    "  $$ \\hat{y}_{RF} = \\frac{1}{T} \\sum_{t=1}^{T} f_t(x) $$\n",
    "\n",
    "- **AdaBoost (Adaptive Boosting)**: Constrói árvores sequencialmente, onde cada modelo tenta **corrigir os erros do modelo anterior**. Os exemplos mal classificados recebem pesos maiores para influenciar mais a próxima árvore.\n",
    "\n",
    "### **Redução do Erro**\n",
    "- **Random Forest**: Reduz a **variância** ao combinar várias árvores de decisão, melhorando a **generalização do modelo**.\n",
    "- **AdaBoost**: Foca na **redução do viés**, aprimorando a **capacidade do modelo de aprender padrões complexos**, mas pode ser mais sensível a **outliers**.\n",
    "\n",
    "### **Complexidade dos Modelos Base**\n",
    "- **Random Forest**: Usa **árvores profundas** como base learners.\n",
    "- **AdaBoost**: Frequentemente utiliza **árvores rasas** (stumps, com `max_depth=1`) como base learners.\n",
    "\n",
    "### **Ponderação das Previsões**\n",
    "- **Random Forest**: Todas as árvores têm **peso igual** no ensemble.\n",
    "- **AdaBoost**: Árvores com **melhor desempenho** recebem maior peso, enquanto modelos fracos têm menos influência.\n",
    "\n",
    "  $$ \\alpha_t = \\frac{1}{2} \\ln \\left( \\frac{1 - e_t}{e_t} \\right) $$\n",
    "\n",
    "  onde:\n",
    "  - $e_t$ é o erro da $t$-ésima árvore.\n",
    "  - $\\alpha_t$ é o peso atribuído à árvore na combinação final.\n",
    "\n",
    "### **Sensibilidade a Dados Ruidosos**\n",
    "- **Random Forest**: Mais **robusto a outliers** devido ao uso do **bootstrap** e da agregação de múltiplos modelos.\n",
    "- **AdaBoost**: Pode ser **mais sensível** a outliers, pois foca mais nos exemplos difíceis de classificar.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feff3a24-a210-4621-919d-97024800c0c4",
   "metadata": {},
   "source": [
    "## **2. Implementação do AdaBoost no Scikit-Learn**\n",
    "O código abaixo implementa o **AdaBoostClassifier** utilizando o conjunto de dados **Iris**. O desempenho do modelo é avaliado por **validação cruzada** (`cross_val_score`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a1819c-32c7-4923-a726-316782116e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets        import load_iris\n",
    "from sklearn.ensemble        import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0424eee9-4d7c-4b5d-a49e-db5a1aba574f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9466666666666665"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y   = load_iris(return_X_y=True)\n",
    "\n",
    "clf    = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "scores = cross_val_score(estimator=clf, \n",
    "                         X=X, \n",
    "                         y=y, \n",
    "                         cv=5)\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d49e8a9-17c5-4a26-8acc-c73363ef763e",
   "metadata": {},
   "source": [
    "## **3. Principais Hiperparâmetros do AdaBoost**\n",
    "O desempenho do AdaBoost pode ser otimizado ajustando seus **hiperparâmetros**. Aqui estão os mais importantes:\n",
    "\n",
    "#### **`n_estimators` (Número de Estimadores)**\n",
    "- Define o **número de aprendizes fracos**.\n",
    "- Maior valor tende a melhorar a acurácia, mas pode causar **overfitting**.\n",
    "\n",
    "#### **`learning_rate` (Taxa de Aprendizado)**\n",
    "- Controla a contribuição de cada classificador no ensemble.\n",
    "- Valores muito altos podem causar **oscilação**, enquanto valores muito baixos podem dificultar a convergência.\n",
    "\n",
    "#### **`base_estimator` (Modelo Base)**\n",
    "- Define o **aprendiz fraco** usado no boosting (padrão: `DecisionTreeClassifier(max_depth=1)`).\n",
    "\n",
    "#### **`algorithm` (Algoritmo de Atualização)**\n",
    "- `SAMME`: Versão discreta do AdaBoost (usa pesos de classificação).\n",
    "- `SAMME.R`: Versão que usa probabilidades e geralmente tem **melhor desempenho**.\n",
    "\n",
    "#### **`random_state` (Reprodutibilidade)**\n",
    "- Define um **seed** para manter resultados consistentes.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Otimização do AdaBoost com GridSearch**\n",
    "Ajustamos o hiperparâmetro **`n_estimators`** para encontrar o número ideal de estimadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "417b7e95-c484-40cf-bc26-0fdd88e5d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28f905aa-f7cb-460f-8522-e87a602e421c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.4 s, sys: 582 ms, total: 45.9 s\n",
      "Wall time: 46.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>0.953333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>401</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>501</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>601</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>701</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>801</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1001</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimators  mean_score\n",
       "0              1    0.666667\n",
       "1            101    0.953333\n",
       "2            201    0.946667\n",
       "3            301    0.946667\n",
       "4            401    0.946667\n",
       "5            501    0.946667\n",
       "6            601    0.946667\n",
       "7            701    0.946667\n",
       "8            801    0.946667\n",
       "9            901    0.946667\n",
       "10          1001    0.946667"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "estimators = list(range(1, 1002, 100))\n",
    "\n",
    "n_estimators = []\n",
    "mean_scores  = []\n",
    "\n",
    "for n in estimators:\n",
    "    clf    = AdaBoostClassifier(n_estimators=n)\n",
    "    scores = cross_val_score(estimator=clf, \n",
    "                             X=X, \n",
    "                             y=y, \n",
    "                             cv=5)\n",
    "    n_estimators.append(n)\n",
    "    mean_scores.append(scores.mean())\n",
    "\n",
    "pd.DataFrame(data=list(zip(n_estimators, mean_scores)), \n",
    "             columns=['n_estimators', 'mean_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921159d5-086f-44d0-a8dc-1f222c0e7d9e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e1a0dd-9b92-488f-8af3-162c5fa52d25",
   "metadata": {},
   "source": [
    "### **Interpretação dos Resultados**\n",
    "- **Com `n_estimators=1`**, a acurácia é baixa (66.67%), indicando um modelo muito fraco.\n",
    "- A acurácia **aumenta rapidamente** até `n_estimators=101`, atingindo 95.33%.\n",
    "- Após **201 estimadores**, a melhoria é marginal, sugerindo que adicionar mais árvores **não traz ganhos significativos**.\n",
    "\n",
    "Um bom ponto de equilíbrio entre desempenho e eficiência computacional pode ser **`n_estimators=101`**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusão**\n",
    "- **Random Forest** é mais adequado para **redução de variância**, sendo mais robusto a outliers e overfitting.  \n",
    "- **AdaBoost** foca na **redução do viés**, priorizando exemplos mal classificados para melhorar a aprendizagem.  \n",
    "- **Otimizar hiperparâmetros**, como `n_estimators` e `learning_rate`, melhora significativamente o desempenho do AdaBoost.  \n",
    "\n",
    "A escolha entre **Random Forest** e **AdaBoost** deve considerar **as características do problema** e **a necessidade de equilíbrio entre viés e variância**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95beb1b-e4aa-45a6-8c99-6176f2222826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
