{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "166f6f33-c507-4fc6-9ebd-9986eb51ea53",
   "metadata": {},
   "source": [
    "# Implementação do Algoritmo Random Forest\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb6a816-ff6f-403b-8622-0ca33cea960b",
   "metadata": {},
   "source": [
    "O **Random Forest** é um dos algoritmos mais poderosos e amplamente utilizados em Machine Learning, baseado na técnica de ensemble learning. Ele combina múltiplas árvores de decisão para melhorar a estabilidade e a precisão das previsões, reduzindo a variância e mitigando o overfitting. Abaixo, descrevemos as etapas principais para sua implementação:\n",
    "\n",
    "1. **Bootstrap (Amostragem com Reposição)**  \n",
    "   - O conjunto de dados original é dividido em várias amostras bootstrap.  \n",
    "   - Cada amostra bootstrap é gerada por amostragem com reposição, permitindo que certos exemplos sejam selecionados múltiplas vezes.  \n",
    "   - O tamanho de cada amostra bootstrap é igual ao do conjunto de treinamento original.\n",
    "\n",
    "2. **Feature Selection (Seleção Aleatória de Variáveis)**  \n",
    "   - Diferentemente do Bagging tradicional, o Random Forest introduz aleatoriedade adicional ao selecionar um subconjunto aleatório de variáveis para cada divisão de nó em uma árvore.  \n",
    "   - O número de variáveis selecionadas em cada divisão segue uma regra predefinida, geralmente a raiz quadrada do número total de variáveis no caso de classificação e um terço do total no caso de regressão.\n",
    "\n",
    "3. **Modelagem com Árvores de Decisão (Base Learners)**  \n",
    "   - Para cada amostra bootstrap, um modelo de árvore de decisão é treinado independentemente.  \n",
    "   - Não há poda (pruning) das árvores, permitindo que cada uma cresça até o seu máximo potencial.\n",
    "\n",
    "4. **Agregação das Predições (Voting ou Média)**  \n",
    "   - Para tarefas de **classificação**, a agregação final ocorre por meio de uma **votação majoritária**, onde a classe mais predita entre todas as árvores se torna a saída final.  \n",
    "   - Para tarefas de **regressão**, a agregação é feita calculando a **média das previsões** das árvores individuais.  \n",
    "\n",
    "Essa abordagem garante que o **Random Forest** seja um modelo altamente eficaz, pois equilibra viés e variância de maneira mais eficiente do que um único modelo de árvore de decisão.\n",
    "\n",
    "---\n",
    "\n",
    "## **Diferença entre Bagging e Random Forest**\n",
    "\n",
    "Embora o **Bagging (Bootstrap Aggregating)** e o **Random Forest** compartilhem o mesmo princípio fundamental de combinar múltiplos modelos para reduzir a variância e aumentar a estabilidade preditiva, existem diferenças cruciais entre eles:\n",
    "\n",
    "1. **Estratégia de Modelagem:**  \n",
    "   - O **Bagging** é uma abordagem geral de ensemble learning que pode ser aplicada a qualquer modelo base, como árvores de decisão, regressões lineares, entre outros.  \n",
    "   - O **Random Forest**, por outro lado, é uma implementação específica do Bagging que se restringe ao uso de **árvores de decisão**, incorporando uma etapa adicional de seleção aleatória de variáveis para cada divisão de nó.\n",
    "\n",
    "2. **Diversificação dos Modelos:**  \n",
    "   - No **Bagging**, cada modelo base é treinado em um subconjunto bootstrap, mas todas as variáveis podem ser consideradas em cada divisão da árvore.  \n",
    "   - No **Random Forest**, além de utilizar amostragem bootstrap, um subconjunto aleatório de variáveis é selecionado para cada nó da árvore, reduzindo ainda mais a correlação entre os modelos.\n",
    "\n",
    "3. **Redução da Correlação entre Árvores:**  \n",
    "   - O **Bagging** ajuda a reduzir a variância, mas suas árvores podem permanecer fortemente correlacionadas se todas tiverem acesso a todas as variáveis.  \n",
    "   - O **Random Forest** reduz ainda mais essa correlação ao limitar o número de variáveis disponíveis para cada divisão, tornando as árvores mais independentes e aumentando a generalização do modelo.\n",
    "\n",
    "Em resumo, o **Random Forest** pode ser visto como uma versão otimizada do **Bagging**, projetada especificamente para árvores de decisão. Essa técnica introduz maior diversidade entre os modelos individuais, levando a um desempenho geralmente superior em termos de precisão e robustez.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a698d4e7-cef9-411a-9227-f6a0ce9e5de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import das bibliotecas:\n",
    "\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets        import load_iris\n",
    "from sklearn.datasets        import load_diabetes\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree            import DecisionTreeClassifier\n",
    "from sklearn.metrics         import accuracy_score\n",
    "\n",
    "from sklearn.tree            import DecisionTreeRegressor\n",
    "from sklearn.metrics         import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9eebb7d-9eda-475d-87f6-a8565dd80612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier()\n",
      "Accuracy score: 0.96\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_test  y_pred\n",
       "0        0       0\n",
       "1        2       2\n",
       "2        1       1\n",
       "3        2       2\n",
       "4        1       1\n",
       "5        2       2\n",
       "6        2       1\n",
       "7        2       2\n",
       "8        1       1\n",
       "9        0       0\n",
       "10       2       2\n",
       "11       2       1\n",
       "12       1       1\n",
       "13       0       0\n",
       "14       0       0\n",
       "15       0       0\n",
       "16       1       1\n",
       "17       1       1\n",
       "18       0       0\n",
       "19       2       2\n",
       "20       2       2\n",
       "21       0       0\n",
       "22       2       2\n",
       "23       2       2\n",
       "24       1       1\n",
       "25       0       0\n",
       "26       0       0\n",
       "27       2       2\n",
       "28       1       1\n",
       "29       0       0\n",
       "30       0       0\n",
       "31       0       0\n",
       "32       0       0\n",
       "33       2       2\n",
       "34       2       2\n",
       "35       1       1\n",
       "36       1       1\n",
       "37       0       0\n",
       "38       2       2\n",
       "39       1       1\n",
       "40       0       0\n",
       "41       2       2\n",
       "42       2       2\n",
       "43       0       0\n",
       "44       2       2\n",
       "45       2       2\n",
       "46       0       0\n",
       "47       1       1\n",
       "48       1       1\n",
       "49       1       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo da técnica Random Forest para problemas de classificação:\n",
    "\n",
    "X = load_iris().data\n",
    "y = load_iris().target\n",
    "\n",
    "df = pd.DataFrame(X, columns=load_iris().feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "def rf_classifier(df:pd.DataFrame, \n",
    "                  num_bootstrap_samples:int=3,  # Parâmetro da função que define a quantidade de amostragens para treinamento\n",
    "                  test_size:float=0.25\n",
    "                 ) -> pd.DataFrame:\n",
    "    \n",
    "    df_train, df_test = train_test_split(df, test_size=test_size)\n",
    "    \n",
    "    X_test = df_test.drop(['target'], axis=1)\n",
    "    y_test = df_test['target'].rename('y_test')\n",
    "    \n",
    "    # Dicionário para os resultados das predições de cada modelo\n",
    "    y_pred_bagging = {}\n",
    "\n",
    "    for i in range(num_bootstrap_samples):\n",
    "        # Bootstrap\n",
    "        df_train = df_train.sample(n=len(df_train), \n",
    "                                   replace=True)  # Amostragem COM reposição\n",
    "\n",
    "        X_train = df_train.drop(['target'], axis=1)\n",
    "        # Feature selection\n",
    "        X_train = X_train.sample(n=round(np.sqrt(X_train.shape[1])),  # Cálculo da raiz quadrada da quantidade de variáveis\n",
    "                                 axis=1)\n",
    "        \n",
    "        y_train = df_train['target']\n",
    "        \n",
    "        # Modelagem (base learners)\n",
    "        model = DecisionTreeClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Adicionando os resultados do modelo ao dicionário para agregação das predições\n",
    "        y_pred_bagging.update({i:model.predict(X_test[X_train.columns])})\n",
    "    \n",
    "    # Aggregating\n",
    "    y_pred = (pd.DataFrame(y_pred_bagging)\n",
    "                .mode(axis=1)  # Agregando o valor com maior número de aparições nas predições dos modelos\n",
    "                .rename(columns={0:'y_pred'}))\n",
    " \n",
    "    # Resultados\n",
    "    print(model)\n",
    "    print('Accuracy score:', accuracy_score(y_true=y_test, \n",
    "                                            y_pred=y_pred['y_pred']\n",
    "                                           ))\n",
    "\n",
    "    return pd.concat(objs=[y_test.reset_index(drop=True), \n",
    "                           y_pred['y_pred'].astype(int)], \n",
    "                     axis=1)\n",
    "\n",
    "rf_classifier(num_bootstrap_samples=10, df=df, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c44692d5-b1a0-4351-af50-6941709045c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor()\n",
      "Mean squared error: 4199.046575342466\n",
      "Coefficient of determination: 0.271689234225421\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>155.0</td>\n",
       "      <td>121.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72.0</td>\n",
       "      <td>155.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197.0</td>\n",
       "      <td>187.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154.0</td>\n",
       "      <td>141.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>277.0</td>\n",
       "      <td>217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>148.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>198.0</td>\n",
       "      <td>123.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>199.0</td>\n",
       "      <td>133.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>270.0</td>\n",
       "      <td>190.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>91.0</td>\n",
       "      <td>163.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  y_pred\n",
       "0     155.0   121.3\n",
       "1      72.0   155.2\n",
       "2     197.0   187.5\n",
       "3     154.0   141.5\n",
       "4     277.0   217.0\n",
       "..      ...     ...\n",
       "141   148.0   153.0\n",
       "142   198.0   123.6\n",
       "143   199.0   133.3\n",
       "144   270.0   190.4\n",
       "145    91.0   163.3\n",
       "\n",
       "[146 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo da técnica Random Forest para problemas de regressão:\n",
    "\n",
    "X = load_diabetes().data\n",
    "y = load_diabetes().target\n",
    "\n",
    "df = pd.DataFrame(X, columns=load_diabetes().feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "def rf_regressor(df:pd.DataFrame, \n",
    "                 num_bootstrap_samples:int=3,  # Parâmetro da função que define a quantidade de amostragens para treinamento\n",
    "                 test_size:float=0.25\n",
    "                ) -> pd.DataFrame:\n",
    "    \n",
    "    df_train, df_test = train_test_split(df, test_size=test_size)\n",
    "    \n",
    "    X_test = df_test.drop(['target'], axis=1)\n",
    "    y_test = df_test['target'].rename('y_test')\n",
    "    \n",
    "    # Dicionário para os resultados das predições de cada modelo\n",
    "    y_pred_bagging = {}\n",
    "\n",
    "    for i in range(num_bootstrap_samples):\n",
    "        # Bootstrap\n",
    "        df_train = df_train.sample(n=len(df_train), \n",
    "                                   replace=True)  # Amostragem COM reposição\n",
    "\n",
    "        X_train = df_train.drop(['target'], axis=1)\n",
    "        # Feature selection\n",
    "        X_train = X_train.sample(n=round(X_train.shape[1]/3),  # Cálculo da quantidade de variáveis dividida por 3\n",
    "                                 axis=1)\n",
    "        \n",
    "        y_train = df_train['target']\n",
    "\n",
    "        # Modelagem (base learners)\n",
    "        model = DecisionTreeRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Adicionando os resultados do modelo ao dicionário para agregação das predições\n",
    "        y_pred_bagging.update({i:model.predict(X_test[X_train.columns])})\n",
    "\n",
    "    # Aggregating\n",
    "    y_pred = (pd.DataFrame(y_pred_bagging)\n",
    "                .mean(axis=1)  # Agregando as predições dos modelos baseando n a média dos resultados\n",
    "                .rename('y_pred'))\n",
    " \n",
    "    # Resultados\n",
    "    print(model)\n",
    "    print('Mean squared error:', mean_squared_error(y_true=y_test, \n",
    "                                                   y_pred=y_pred))\n",
    "    print('Coefficient of determination:', r2_score(y_true=y_test, \n",
    "                                                    y_pred=y_pred))\n",
    "    \n",
    "    return pd.concat(objs=[y_test.reset_index(drop=True), \n",
    "                           y_pred], \n",
    "                     axis=1)\n",
    "    \n",
    "rf_regressor(num_bootstrap_samples=10, df=df, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afea5b5-6bed-4c12-adf1-988ce95e0db1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aaacd0-6dab-42fd-ab1a-eca483b4813f",
   "metadata": {},
   "source": [
    "## **Conclusão**\n",
    "\n",
    "A implementação do **Random Forest** em problemas de **classificação** e **regressão** demonstrou sua eficácia como um modelo preditivo robusto.  \n",
    "\n",
    "### **Resultados Obtidos**\n",
    "**Classificação**  \n",
    "- O modelo alcançou uma **acurácia de 96%**, evidenciando que a agregação de múltiplas árvores reduziu significativamente a variância e melhorou a estabilidade da previsão.  \n",
    "- O uso de seleção aleatória de variáveis garantiu que diferentes árvores explorassem padrões distintos nos dados, resultando em um desempenho superior ao de uma única árvore de decisão.\n",
    "\n",
    "**Regressão**  \n",
    "- O **Erro Quadrático Médio (MSE)** foi **4199,05**, e o coeficiente de determinação (**R²**) atingiu **0,27**.  \n",
    "- Embora o desempenho tenha sido inferior ao da classificação, o modelo ainda conseguiu capturar uma parte significativa da variabilidade nos dados.  \n",
    "- A otimização dos hiperparâmetros, como o número de árvores e a profundidade máxima das árvores individuais, poderia melhorar os resultados.\n",
    "\n",
    "### **Considerações Finais**\n",
    "O **Random Forest** provou ser um modelo altamente eficiente para tarefas de Machine Learning, combinando a simplicidade das árvores de decisão com a robustez dos métodos de ensemble. Sua capacidade de lidar com conjuntos de dados complexos, minimizando overfitting e maximizando a generalização, faz dele uma das abordagens mais confiáveis para modelagem preditiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c2d70e-470c-44ed-9ba7-97bbc26f0c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
