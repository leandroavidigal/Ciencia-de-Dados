# ğŸŒ³ Modelagem Preditiva com Ãrvores de DecisÃ£o

## ğŸ“– Sobre o Projeto
Este projeto termos a construÃ§Ã£o e otimizaÃ§Ã£o de **Ãrvores de DecisÃ£o**, uma das tÃ©cnicas mais interpretÃ¡veis do aprendizado de mÃ¡quina, aplicadas a dois cenÃ¡rios distintos:

1. **PrediÃ§Ã£o de InadimplÃªncia** ğŸš€ â€“ Desenvolvimento de um modelo preditivo para identificar clientes inadimplentes com base em dados cadastrais e financeiros.
2. **PrevisÃ£o de PreÃ§os ImobiliÃ¡rios** ğŸ¡ â€“ ConstruÃ§Ã£o de uma Ã¡rvore de regressÃ£o para estimar o valor mediano das casas ocupadas pelo proprietÃ¡rio, utilizando dados socioeconÃ´micos e ambientais.

## ğŸ” Objetivos do Projeto
âœ… **ExploraÃ§Ã£o e limpeza dos dados** para garantir qualidade e consistÃªncia.
âœ… **ConversÃ£o de variÃ¡veis categÃ³ricas em numÃ©ricas**, facilitando o uso no scikit-learn.
âœ… **ConstruÃ§Ã£o de Ãrvores de DecisÃ£o** para classificaÃ§Ã£o e regressÃ£o.
âœ… **OtimizaÃ§Ã£o dos modelos** por meio da tÃ©cnica CCP-alpha pruning.
âœ… **AvaliaÃ§Ã£o do desempenho** utilizando mÃ©tricas como acurÃ¡cia, erro quadrÃ¡tico mÃ©dio (MSE) e coeficiente de determinaÃ§Ã£o (RÂ²).
âœ… **InterpretaÃ§Ã£o dos modelos** para extrair insights valiosos e aplicÃ¡veis ao mundo real.

## ğŸ› ï¸ Tecnologias Utilizadas
O projeto foi desenvolvido utilizando as seguintes tecnologias:
- **Python** 
- **Pandas** para manipulaÃ§Ã£o de dados
- **Seaborn e Matplotlib** para visualizaÃ§Ã£o
- **scikit-learn** para modelagem preditiva
- **DecisionTreeClassifier e DecisionTreeRegressor** para construÃ§Ã£o das Ã¡rvores

## ğŸ“Š Resultados e ConclusÃµes
ğŸ”¹ **O modelo de inadimplÃªncia** identificou padrÃµes significativos em variÃ¡veis como **posse de veÃ­culo** e **tipo de renda**, auxiliando na previsÃ£o de clientes de risco.
ğŸ”¹ **A Ã¡rvore de regressÃ£o imobiliÃ¡ria** destacou que variÃ¡veis como **nÃºmero mÃ©dio de quartos por habitaÃ§Ã£o (RM)** e **status socioeconÃ´mico da populaÃ§Ã£o (LSTAT)** sÃ£o os principais fatores na definiÃ§Ã£o de preÃ§os.
ğŸ”¹ **O CCP-alpha pruning** melhorou a generalizaÃ§Ã£o dos modelos, reduzindo overfitting e mantendo alta performance nos dados de teste.

ğŸš€ **Bons estudos e boas anÃ¡lises preditivas!**

